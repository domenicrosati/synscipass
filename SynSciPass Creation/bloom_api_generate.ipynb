{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_TOKEN=<your_token>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "API_URL = \"https://api-inference.huggingface.co/models/bigscience/bloom\"\n",
    "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "def query(payload):\n",
    "    data = json.dumps(payload)\n",
    "    response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
    "    return json.loads(response.content.decode(\"utf-8\"))\n",
    "\n",
    "data = query(\n",
    "    {\"inputs\":\"Directional distance functions provide very flexible tools for investigating the performance of Decision Making Units (DMUs).\",\n",
    "    \"parameters\":{\"seed\":42,\"early_stopping\":False,\"length_penalty\":0,\"max_new_tokens\":128,\"do_sample\":True,\"top_p\":0.9}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def construct_passage(first_sentence, max_num_sentences=8):\n",
    "    \"\"\"\n",
    "    Construct a passage from the first sentence.\n",
    "    \"\"\"\n",
    "    passage_all = first_sentence\n",
    "    range_var = np.random.randint(4, max_num_sentences)\n",
    "    for _ in range(range_var):\n",
    "        data = None\n",
    "        try:\n",
    "            # get the last 512 characters of the passages\n",
    "            passage_that_fits = passage_all[-128:]\n",
    "            data = query(\n",
    "                {\"inputs\": passage_that_fits,\n",
    "                \"parameters\":{\"seed\":45,\"early_stopping\":True,\"length_penalty\":0, \"return_full_text\": False, \"max_new_tokens\":64, \"do_sample\":True,\"top_p\":0.9}}\n",
    "            )\n",
    "            passage_all += data[0][\"generated_text\"]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            if data:\n",
    "                print(data)\n",
    "    return passage_all.replace(first_sentence, '')\n",
    "\n",
    "print(construct_passage(\"Directional distance functions provide very flexible tools for investigating the performance of Decision Making Units (DMUs).\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(('./real_passages_100k.csv'))\n",
    "samples = df.sample(n=1000, random_state=3).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch bloom_passages.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from csv import writer\n",
    "RESUME = 437\n",
    "passages = []\n",
    "j = 0\n",
    "for i, sample in tqdm(samples.iterrows(), total=len(samples)):\n",
    "    j += 1\n",
    "    if j < RESUME:\n",
    "        continue\n",
    "    new_passage = construct_passage(sample['passages'])\n",
    "    passages.append(\n",
    "        new_passage\n",
    "    )\n",
    "    with open('bloom_passages.csv', 'a', newline='') as f_object:  \n",
    "        writer_object = writer(f_object)\n",
    "        writer_object.writerow([j, new_passage])  \n",
    "        f_object.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "passages = pd.read_csv('bloom_passages.csv', header=0, names=['passage_number', 'passage']).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "SIMILARITY_THRESHOLD = 0.8\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages.iloc[2]['passage'].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = []\n",
    "for i, passage in passages.iterrows():\n",
    "    try:\n",
    "        original = samples.iloc[passage['passage_number']]['passages']\n",
    "        para = passage['passage']\n",
    "        if para.strip() == '':\n",
    "            continue\n",
    "        if similar(para, original) >= SIMILARITY_THRESHOLD:\n",
    "            continue\n",
    "        \n",
    "        sentences = para.split('\\n')\n",
    "        reconstructed_sentence = []\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            if  i == len(sentences) - 1:\n",
    "                reconstructed_sentence.append(sentence)\n",
    "            elif similar(sentence, sentences[i+1]) >= 0.1:\n",
    "                print(\n",
    "                    sentence, sentences[i+1]\n",
    "                )\n",
    "            else:\n",
    "                reconstructed_sentence.append(sentence)\n",
    "        clean.append('\\n'.join(reconstructed_sentence))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"passages\": clean\n",
    "})\n",
    "df.to_csv('./bloom_generate.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "0eac3aca0a2c20bfdbdb5cb1114d87c3f5973156693657815379bd068b20371c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
