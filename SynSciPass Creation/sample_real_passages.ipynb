{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample real passages of scientific papers\n",
    "\n",
    "100k passages From the scientific_papers dataset (pubmed+arxiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset scientific_papers (/Users/anon/.cache/huggingface/datasets/scientific_papers/pubmed/1.1.1/306757013fb6f37089b6a75469e6638a553bd9f009484938d8f75a4c5e84206f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcf13ab503e42738afd1990b1586ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset scientific_papers/arxiv (download: 4.20 GiB, generated: 7.06 GiB, post-processed: Unknown size, total: 11.26 GiB) to /Users/anon/.cache/huggingface/datasets/scientific_papers/arxiv/1.1.1/306757013fb6f37089b6a75469e6638a553bd9f009484938d8f75a4c5e84206f...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13dc96beb207482f843b6b0b7746b8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ee1ba5bb0144b5a44114015352bc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3406336e642e40ab9a614ea7d00621ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/203037 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9bd8d9a607f45cf84cb4cd749bfe429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/6436 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76dae3501a5444a38614896e3cdb6e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/6440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset scientific_papers downloaded and prepared to /Users/anon/.cache/huggingface/datasets/scientific_papers/arxiv/1.1.1/306757013fb6f37089b6a75469e6638a553bd9f009484938d8f75a4c5e84206f. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5cc71f128c47f9a038fe1dafd58634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scientific_papers_pubmed = load_dataset('scientific_papers', 'pubmed')\n",
    "scientific_papers_arxiv = load_dataset('scientific_papers', 'arxiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'abstract', 'section_names'],\n",
       "        num_rows: 203037\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'abstract', 'section_names'],\n",
       "        num_rows: 6436\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'abstract', 'section_names'],\n",
       "        num_rows: 6440\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scientific_papers_arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_SEED = 42\n",
    "SAMPLE_NUMBER = 100_000\n",
    "scientific_papers = concatenate_datasets([scientific_papers_pubmed['train'], scientific_papers_arxiv['train']]).shuffle(seed=PAPER_SEED)\n",
    "scientific_papers = scientific_papers.select(range(SAMPLE_NUMBER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5299c395fab74a8b9e7c91513cecd402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def generate_passages(papers, passages_min=1, passages_max=10):\n",
    "    passages = []\n",
    "    for paper in tqdm(papers):\n",
    "        passages_raw = paper.split('\\n')\n",
    "        # # select a random contiguous passage\n",
    "        num_passages = np.random.randint(passages_min, passages_max)\n",
    "        passage_start = np.random.randint(0, len(passages_raw))\n",
    "        passage_end = passage_start + num_passages\n",
    "        passages.append(\n",
    "            ''.join(passages_raw[passage_start:passage_end])\n",
    "        )\n",
    "    return passages\n",
    "passages = generate_passages(scientific_papers['article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100000.000000\n",
       "mean        142.067450\n",
       "std         110.847073\n",
       "min           0.000000\n",
       "25%          60.000000\n",
       "50%         124.000000\n",
       "75%         203.000000\n",
       "max        6576.000000\n",
       "Name: passages, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"passages\": passages\n",
    "})\n",
    "df.to_csv('./real_passages_100k.csv', index=False)\n",
    "df[\"passages\"].apply(lambda s: len(s.split())).describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0eac3aca0a2c20bfdbdb5cb1114d87c3f5973156693657815379bd068b20371c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
