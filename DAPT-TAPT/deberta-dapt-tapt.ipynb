{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-30T14:58:03.708043Z","iopub.status.busy":"2022-06-30T14:58:03.707283Z","iopub.status.idle":"2022-06-30T14:58:11.635315Z","shell.execute_reply":"2022-06-30T14:58:11.634122Z","shell.execute_reply.started":"2022-06-30T14:58:03.707903Z"},"trusted":true},"outputs":[],"source":["!apt-get install git-lfs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-30T14:58:12.825778Z","iopub.status.busy":"2022-06-30T14:58:12.825149Z","iopub.status.idle":"2022-06-30T14:58:25.306509Z","shell.execute_reply":"2022-06-30T14:58:25.305182Z","shell.execute_reply.started":"2022-06-30T14:58:12.825740Z"},"trusted":true},"outputs":[],"source":["pip install datasets transformers torch numpy sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-30T14:58:25.308803Z","iopub.status.busy":"2022-06-30T14:58:25.308498Z","iopub.status.idle":"2022-06-30T14:58:25.314736Z","shell.execute_reply":"2022-06-30T14:58:25.313676Z","shell.execute_reply.started":"2022-06-30T14:58:25.308774Z"},"trusted":true},"outputs":[],"source":["import os\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-30T14:58:25.316533Z","iopub.status.busy":"2022-06-30T14:58:25.316172Z","iopub.status.idle":"2022-06-30T14:59:27.277253Z","shell.execute_reply":"2022-06-30T14:59:27.276143Z","shell.execute_reply.started":"2022-06-30T14:58:25.316495Z"},"trusted":true},"outputs":[],"source":["import datasets\n","from transformers import AutoModelForMaskedLM, AutoTokenizer, Trainer, TrainingArguments\n","\n","model_checkpoint = \"anon/deberta-v3-large-dapt-scientific-papers-pubmed\"\n","model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-30T14:59:27.284340Z","iopub.status.busy":"2022-06-30T14:59:27.280564Z","iopub.status.idle":"2022-06-30T14:59:30.262618Z","shell.execute_reply":"2022-06-30T14:59:30.261529Z","shell.execute_reply.started":"2022-06-30T14:59:27.284285Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import torch\n","\n","text = \"This is a great [MASK].\"\n","inputs = tokenizer(text, return_tensors=\"pt\")\n","token_logits = model(**inputs).logits\n","# Find the location of [MASK] and extract its logits\n","mask_token_index = np.argwhere(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1, 0]\n","mask_token_logits = token_logits[0, mask_token_index, :].detach().numpy()\n","# Pick the [MASK] candidates with the highest logits\n","# We negate the array before argsort to get the largest, not the smallest, logits\n","top_5_tokens = np.argsort(-mask_token_logits)[:5].tolist()\n","\n","for token in top_5_tokens:\n","    print(f\">>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-30T14:59:30.265050Z","iopub.status.busy":"2022-06-30T14:59:30.263963Z","iopub.status.idle":"2022-06-30T14:59:30.701512Z","shell.execute_reply":"2022-06-30T14:59:30.700446Z","shell.execute_reply.started":"2022-06-30T14:59:30.265005Z"},"trusted":true},"outputs":[],"source":["train_dataset = datasets.load_dataset(\n","    'csv', \n","    data_files={\n","        'train': \"../input/detecting-generated-scientific-papers/fake_papers_train_part_public.csv\",\n","        \n","    },\n","\n",").remove_columns(['id', 'fake'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-30T14:59:30.704050Z","iopub.status.busy":"2022-06-30T14:59:30.702986Z","iopub.status.idle":"2022-06-30T14:59:31.406234Z","shell.execute_reply":"2022-06-30T14:59:31.405155Z","shell.execute_reply.started":"2022-06-30T14:59:30.704011Z"},"trusted":true},"outputs":[],"source":["test_dataset = datasets.load_dataset(\n","    'csv', \n","    data_files={\n","        'train': \"../input/detecting-generated-scientific-papers/fake_papers_test_public.csv\",\n","        \n","    },\n","\n",").remove_columns(['id'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-30T14:59:31.408607Z","iopub.status.busy":"2022-06-30T14:59:31.407895Z","iopub.status.idle":"2022-06-30T14:59:31.417912Z","shell.execute_reply":"2022-06-30T14:59:31.416836Z","shell.execute_reply.started":"2022-06-30T14:59:31.408567Z"},"trusted":true},"outputs":[],"source":["test_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-30T14:59:31.420365Z","iopub.status.busy":"2022-06-30T14:59:31.419561Z","iopub.status.idle":"2022-06-30T14:59:31.433707Z","shell.execute_reply":"2022-06-30T14:59:31.432601Z","shell.execute_reply.started":"2022-06-30T14:59:31.420325Z"},"trusted":true},"outputs":[],"source":["dataset = datasets.concatenate_datasets(\n","    [test_dataset['train'], train_dataset['train']]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-30T14:59:31.436438Z","iopub.status.busy":"2022-06-30T14:59:31.435659Z","iopub.status.idle":"2022-06-30T15:00:12.874715Z","shell.execute_reply":"2022-06-30T15:00:12.873557Z","shell.execute_reply.started":"2022-06-30T14:59:31.436386Z"},"trusted":true},"outputs":[],"source":["\n","def tokenize_function(examples):\n","    result = tokenizer(examples[\"text\"])\n","    if tokenizer.is_fast:\n","        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n","    return result\n","\n","\n","# Use batched=True to activate fast multithreading!\n","tokenized_datasets = dataset.map(\n","    tokenize_function, batched=True, remove_columns=[\"text\"]\n",")\n","tokenized_datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-30T15:00:12.879440Z","iopub.status.busy":"2022-06-30T15:00:12.878802Z","iopub.status.idle":"2022-06-30T15:00:52.849189Z","shell.execute_reply":"2022-06-30T15:00:52.848150Z","shell.execute_reply.started":"2022-06-30T15:00:12.879410Z"},"trusted":true},"outputs":[],"source":["chunk_size = 128\n","def group_texts(examples):\n","    # Concatenate all texts\n","    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n","    # Compute length of concatenated texts\n","    total_length = len(concatenated_examples[list(examples.keys())[0]])\n","    # We drop the last chunk if it's smaller than chunk_size\n","    total_length = (total_length // chunk_size) * chunk_size\n","    # Split by chunks of max_len\n","    result = {\n","        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n","        for k, t in concatenated_examples.items()\n","    }\n","    # Create a new labels column\n","    result[\"labels\"] = result[\"input_ids\"].copy()\n","    return result\n","\n","lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n","lm_datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-30T15:00:52.851224Z","iopub.status.busy":"2022-06-30T15:00:52.850825Z","iopub.status.idle":"2022-06-30T15:00:52.856913Z","shell.execute_reply":"2022-06-30T15:00:52.855837Z","shell.execute_reply.started":"2022-06-30T15:00:52.851187Z"},"trusted":true},"outputs":[],"source":["from transformers import DataCollatorForLanguageModeling\n","\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-30T15:00:52.860849Z","iopub.status.busy":"2022-06-30T15:00:52.860183Z","iopub.status.idle":"2022-06-30T15:00:53.079856Z","shell.execute_reply":"2022-06-30T15:00:53.078736Z","shell.execute_reply.started":"2022-06-30T15:00:52.860805Z"},"trusted":true},"outputs":[],"source":["train_size = len(lm_datasets)- 1\n","test_size = int(0.1 * train_size) - 1\n","print(train_size, test_size)\n","\n","downsampled_dataset = lm_datasets.train_test_split(\n","    train_size=train_size - test_size, test_size=test_size, seed=42\n",")\n","downsampled_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-30T15:00:53.081828Z","iopub.status.busy":"2022-06-30T15:00:53.081421Z","iopub.status.idle":"2022-06-30T15:00:53.453180Z","shell.execute_reply":"2022-06-30T15:00:53.452164Z","shell.execute_reply.started":"2022-06-30T15:00:53.081786Z"},"trusted":true},"outputs":[],"source":["metric = datasets.load_metric(\"accuracy\")\n","def preprocess_logits_for_metrics(logits, labels):\n","    if isinstance(logits, tuple):\n","        # Depending on the model and config, logits may contain extra tensors,\n","        # like past_key_values, but logits always come first\n","        logits = logits[0]\n","    return logits.argmax(dim=-1)\n","        \n","def compute_metrics(eval_preds):\n","    preds, labels = eval_preds\n","    # preds have the same shape as the labels, after the argmax(-1) has been calculated\n","    # by preprocess_logits_for_metrics\n","    labels = labels.reshape(-1)\n","    preds = preds.reshape(-1)\n","    mask = labels != -100\n","    labels = labels[mask]\n","    preds = preds[mask]\n","    return metric.compute(predictions=preds, references=labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-30T15:00:53.463223Z","iopub.status.busy":"2022-06-30T15:00:53.459872Z","iopub.status.idle":"2022-06-30T15:09:54.771449Z","shell.execute_reply":"2022-06-30T15:09:54.770243Z","shell.execute_reply.started":"2022-06-30T15:00:53.463168Z"},"trusted":true},"outputs":[],"source":["training_args = TrainingArguments(\n","    \"deberta-v3-large-dapt-scientific-papers-pubmed-tapt\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=5,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"no\",\n","    push_to_hub=True,\n","    fp16=True # switch off if not using GPU\n",")\n","\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=downsampled_dataset['train'],\n","    eval_dataset=downsampled_dataset['test'],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-30T15:09:54.774114Z","iopub.status.busy":"2022-06-30T15:09:54.773686Z","iopub.status.idle":"2022-06-30T19:19:26.231066Z","shell.execute_reply":"2022-06-30T19:19:26.229920Z","shell.execute_reply.started":"2022-06-30T15:09:54.774054Z"},"trusted":true},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-30T19:19:26.232590Z","iopub.status.busy":"2022-06-30T19:19:26.232246Z","iopub.status.idle":"2022-06-30T19:24:24.633938Z","shell.execute_reply":"2022-06-30T19:24:24.632974Z","shell.execute_reply.started":"2022-06-30T19:19:26.232552Z"},"trusted":true},"outputs":[],"source":["trainer.push_to_hub(commit_message=\"Training complete\", tags=\"fill-mask\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
